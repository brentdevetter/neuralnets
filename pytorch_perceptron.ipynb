{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_perceptron.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rGOaHZXjoY9w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Implement Perceptron using PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "r2ycpKpwoYOk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "a64e34e7-0470-4162-9c1b-92414b5438ae",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522126808832,
          "user_tz": 420,
          "elapsed": 2432,
          "user": {
            "displayName": "Brent DeVetter",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110290226878953433531"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 3-26-2018\n",
        "# Brent DeVetter\n",
        "# Written for the Google CoLab environment \n",
        "#   - Uses PyTorch and requires a GPU (as written)\n",
        "#   - Reference: https://medium.com/@tomgrek/building-your-first-neural-net-from-scratch-with-pytorch-56b0e9c84d54\n",
        "\n",
        "# Import libaries\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd, nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Loss function (mean-squared error, MSE)\n",
        "def criterion(out, label):\n",
        "  return (label - out)**2\n",
        "\n",
        "# Set up a neural network with a bias (b) and weights (A)\n",
        "# No activation function is used here\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()                                                 # pytorch requires this statement\n",
        "    self.fc1 = nn.Linear(in_features=1, out_features=1, bias=True)              # Linear transformation: i.e., y = Ax + b\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    return x   \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  # Create Net instance and print properties\n",
        "  net = Net().cuda()\n",
        "  print(net)\n",
        "  print(list(net.parameters()))\n",
        "  \n",
        "  # Create a random number for the net\n",
        "  input = Variable(torch.randn(1,1,1), requires_grad=True).cuda()\n",
        "  print(\"Input: {0}\".format(input))\n",
        "  \n",
        "  # Test that the network is working\n",
        "  out = net(input)\n",
        "  print(out)\n",
        "  \n",
        "  # Now that we have a working net, train the data. \n",
        "  # Dataset we are trying to train to Ax + b (ie, A = 3, b = 0)\n",
        "  data = [(1,3), (2,6), (3,9), (4,12), (5,15), (6,18)]\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "  \n",
        "  for epoch in range(101):\n",
        "    for i, data2 in enumerate(data):\n",
        "      X, Y = iter(data2)\n",
        "      X, Y = Variable(torch.FloatTensor([X]), requires_grad=True).cuda(), Variable(torch.FloatTensor([Y]), requires_grad=False).cuda()\n",
        "        \n",
        "      optimizer.zero_grad() # This is required don't forget to zero the gradient\n",
        "      y_pred = net(X)\n",
        "      loss = criterion(y_pred, Y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if (epoch % 10 == 0):\n",
        "      print(\"Epoch {0} - loss: {1}\".format(epoch, loss.data[0]))   \n",
        "        \n",
        "        \n",
        "print(list(net.parameters()))        \n",
        "        "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=1, out_features=1)\n",
            ")\n",
            "[Parameter containing:\n",
            " 0.8926\n",
            "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
            ", Parameter containing:\n",
            " 0.1601\n",
            "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
            "]\n",
            "Input: Variable containing:\n",
            "(0 ,.,.) = \n",
            "  1.0524\n",
            "[torch.cuda.FloatTensor of size 1x1x1 (GPU 0)]\n",
            "\n",
            "Variable containing:\n",
            "(0 ,.,.) = \n",
            "  1.0995\n",
            "[torch.cuda.FloatTensor of size 1x1x1 (GPU 0)]\n",
            "\n",
            "Epoch 0 - loss: 0.026212086901068687\n",
            "Epoch 10 - loss: 0.04181097075343132\n",
            "Epoch 20 - loss: 0.01461385004222393\n",
            "Epoch 30 - loss: 0.0051082707941532135\n",
            "Epoch 40 - loss: 0.0017856801860034466\n",
            "Epoch 50 - loss: 0.0006241229129955173\n",
            "Epoch 60 - loss: 0.00021822424605488777\n",
            "Epoch 70 - loss: 7.624506542924792e-05\n",
            "Epoch 80 - loss: 2.6678259018808603e-05\n",
            "Epoch 90 - loss: 9.313225746154785e-06\n",
            "Epoch 100 - loss: 3.2556854421272874e-06\n",
            "[Parameter containing:\n",
            " 2.9993\n",
            "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
            ", Parameter containing:\n",
            "1.00000e-03 *\n",
            "  4.0758\n",
            "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1jusuwa54FeW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1261
        },
        "outputId": "ce1e6b3e-1a2c-46af-b9f4-c71ecd68c949",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522128876898,
          "user_tz": 420,
          "elapsed": 1034,
          "user": {
            "displayName": "Brent DeVetter",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110290226878953433531"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Now, use a ReLU activation function AND a multi-layer perceptron \n",
        "# Note that I found it necessary to change the SGD lr and momentum (especially lr, otherwise massive error was present)\n",
        "\n",
        "# Loss function (mean-squared error, MSE)\n",
        "def criterion(out, label):\n",
        "  return (label - out)**2\n",
        "\n",
        "# Set up a neural network with a bias (b) and weights (A)\n",
        "# No activation function is used here\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()                                                 # pytorch requires this statement\n",
        "    self.fc1 = nn.Linear(in_features=1, out_features=3, bias=True)             # Linear transformation: i.e., y = Ax + b\n",
        "    self.fc2 = nn.Linear(in_features=3, out_features=1, bias=True)\n",
        "  def forward(self, x):\n",
        "    x = self.fc2(F.relu(self.fc1(x)))\n",
        "    return x   \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  # Create Net instance and print properties\n",
        "  net = Net().cuda()\n",
        "  print(net)\n",
        "  print(list(net.parameters()))\n",
        "  \n",
        "  # Create a random number for the net\n",
        "  input = Variable(torch.randn(1,1,1), requires_grad=True).cuda()\n",
        "  print(\"Input: {0}\".format(input))\n",
        "  \n",
        "  # Test that the network is working\n",
        "  out = net(input)\n",
        "  print(out)\n",
        "  \n",
        "  # Now that we have a working net, train the data. \n",
        "  # Dataset we are trying to train to Ax + b (ie, A = 3, b = 0)\n",
        "  data = [(1,3), (2,6), (3,9), (4,12), (5,15), (6,18)]\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.6)\n",
        "  \n",
        "  for epoch in range(101):\n",
        "    for i, data2 in enumerate(data):\n",
        "      X, Y = iter(data2)\n",
        "      X, Y = Variable(torch.FloatTensor([X]), requires_grad=True).cuda(), Variable(torch.FloatTensor([Y]), requires_grad=False).cuda()\n",
        "        \n",
        "      optimizer.zero_grad() # This is required don't forget to zero the gradient\n",
        "      y_pred = net(X)\n",
        "      loss = criterion(y_pred, Y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if (epoch % 10 == 0):\n",
        "      print(\"Epoch {0} - loss: {1}\".format(epoch, loss.data[0]))   \n",
        "        \n",
        "print(\"Optimized parameters: \")\n",
        "print(list(net.parameters()))        \n",
        "        \n",
        "print(\"Prediction: \")  \n",
        "print(net(Variable(torch.Tensor([[[1]]]).cuda())))  "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=1, out_features=3)\n",
            "  (fc2): Linear(in_features=3, out_features=1)\n",
            ")\n",
            "[Parameter containing:\n",
            " 0.5437\n",
            " 0.4377\n",
            "-0.1207\n",
            "[torch.cuda.FloatTensor of size 3x1 (GPU 0)]\n",
            ", Parameter containing:\n",
            " 0.9994\n",
            " 0.0670\n",
            "-0.0591\n",
            "[torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
            ", Parameter containing:\n",
            "-0.4058 -0.1300  0.3575\n",
            "[torch.cuda.FloatTensor of size 1x3 (GPU 0)]\n",
            ", Parameter containing:\n",
            "1.00000e-02 *\n",
            "  4.7812\n",
            "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
            "]\n",
            "Input: Variable containing:\n",
            "(0 ,.,.) = \n",
            "  0.7672\n",
            "[torch.cuda.FloatTensor of size 1x1x1 (GPU 0)]\n",
            "\n",
            "Variable containing:\n",
            "(0 ,.,.) = \n",
            " -0.5794\n",
            "[torch.cuda.FloatTensor of size 1x1x1 (GPU 0)]\n",
            "\n",
            "Epoch 0 - loss: 307.56732177734375\n",
            "Epoch 10 - loss: 0.7161722779273987\n",
            "Epoch 20 - loss: 0.4294607639312744\n",
            "Epoch 30 - loss: 0.2592196762561798\n",
            "Epoch 40 - loss: 0.15642793476581573\n",
            "Epoch 50 - loss: 0.09409399330615997\n",
            "Epoch 60 - loss: 0.056354258209466934\n",
            "Epoch 70 - loss: 0.033598896116018295\n",
            "Epoch 80 - loss: 0.01994742453098297\n",
            "Epoch 90 - loss: 0.01179906539618969\n",
            "Epoch 100 - loss: 0.006957590114325285\n",
            "Optimized parameters: \n",
            "[Parameter containing:\n",
            " 1.2360\n",
            " 1.2282\n",
            "-0.1207\n",
            "[torch.cuda.FloatTensor of size 3x1 (GPU 0)]\n",
            ", Parameter containing:\n",
            " 0.5037\n",
            "-0.3910\n",
            "-0.0591\n",
            "[torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
            ", Parameter containing:\n",
            " 1.0957  1.3083  0.3575\n",
            "[torch.cuda.FloatTensor of size 1x3 (GPU 0)]\n",
            ", Parameter containing:\n",
            " 0.1477\n",
            "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
            "]\n",
            "Prediction: \n",
            "Variable containing:\n",
            "(0 ,.,.) = \n",
            "  3.1494\n",
            "[torch.cuda.FloatTensor of size 1x1x1 (GPU 0)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}